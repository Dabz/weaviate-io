---
title: Using Generative Models in Weaviate 
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import FilteredTextBlock from '@site/src/components/Documentation/FilteredTextBlock';
import TSCode from '!!raw-loader!./_snippets/20_generative.ts';
import WeaviateTypescriptImgUrl from '/developers/academy/js/standalone/using-ml-models/_img/generative.png';


## <i class="fa-solid fa-chalkboard"></i> What are generative models

Generative models are machine learning models that when prompted, can generate original data guided by instructions in the prompt i.e. text, images, and other forms.  This original data is derived from data it was trained on but does not mimic it like for like.  

<img src={WeaviateTypescriptImgUrl} alt="Image alt" width="100%"/>

Generative Models encompass so many types of models, we will specifically focus on large language models (LLMs).

## <i class="fa-solid fa-chalkboard"></i> When to use generative models

Generative models are stars in the limelight of retrieval augmented generation (RAG) and agentic workflows. They are great for... 

- **Translation:** Models can perform zero-shot translate text from one language to another with extremely high accuracy.
- **Code Generation:** Models can take high-level instructions and turn them into functional custom code.
- **Image Generation:** Models can consistently generate high quality images from text instructions in a prompt.


## <i class="fa-solid fa-chalkboard"></i> Applications of generative models


Large Language Models (LLMs), like Anthropics Claudes series of models, or Google's Gemini are specialized types of generative models focused on text data.  These models, like most machine learning models are typically limited to one or more modalities. 

We use modality to describe the type of input or output that a machine learning model can process or interact with to run. Typically, generative modals fall into two buckets, uni-modal or multimodal. 



- Uni-modal generation 

In the context on LLMs, uni-modal generation defines a models ability to generate content and receive instructions in a single modality, this modality is usually text.

<img src={WeaviateTypescriptImgUrl} alt="Image alt" width="90%"/>



- Multimodal Generation
In the context on LLMs, multimodal generation defines a models ability to generate and receive instructions in multiple modalities. This can range from text input to generation or even image input to audio generation. 

<img src={WeaviateTypescriptImgUrl} alt="Image alt" width="90%"/>


### <i class="fa-solid fa-chalkboard"></i> Using generative models in Weaviate

Weaviate is configured to support many generative models and generative model providers. You can even plug in your own generative model too depending on where in the weaviate workflow you need generative capabilities. 


In Weaviate, generative models power our generative search. Lets walk through what its like to use generative models in Weaviate. 

## Step 1: Connect to a Weaviate instance

 <TabItem value="js" label="app.js">
    <FilteredTextBlock
      text={TSCode}
      startMarker="// START Connect"
      endMarker="// END Connect"
      language="js"
    />
  </TabItem>

Initialize your connection with Weaviate and add relevant environment variables necessary to access third party generative models.

## Step 2: Defining a collection with 

 <TabItem value="js" label="app.js">
    <FilteredTextBlock
      text={TSCode}
      startMarker="// START Collection"
      endMarker="// END Collection"
      language="js"
    />
  </TabItem>

When creating a collection in Weaviate, we define what generative model we want to use. In this example we use a text generation model by Cohere to generate new data. 

## Step 3: Importing data 

 <TabItem value="js" label="app.js">
    <FilteredTextBlock
      text={TSCode}
      startMarker="// START Importing"
      endMarker="// END Importing"
      language="js"
    />
  </TabItem>

Once our collection is created, we import data. Our data is vectorized at import time and we can make semantic search queries on it. We can then use the results of these searches as context for our interactions with large language models.

## Step 4: Making a Single Task Generative Search

 <TabItem value="js" label="app.js">
    <FilteredTextBlock
      text={TSCode}
      startMarker="// START SingleGenerative"
      endMarker="// END SingleGenerative"
      language="js"
    />
  </TabItem>

Here we use a `singlePrompt` to make `n` requests to the language model where `n` is the number of responses we get from our search. We use `limit` to strictly define the number of responses we get. We can place responses from each response into our prompt with this format `{ answer }` i.e we want the answer property from our search response to be translated in french. 

## Step 5: Making a grouped Generative Search


 <TabItem value="js" label="app.js">
    <FilteredTextBlock
      text={TSCode}
      startMarker="// START GroupedGenerative"
      endMarker="// END GroupedGenerative"
      language="js"
    />
  </TabItem>

Here we use the `groupedTask` prompt format to group all the response from our search and send them alongside our prompt as context for what ever we are requesting. You can see with `groupedProperties` we only pass the answer property from all the results we get as context to the large language model, giving us control of what information will inform the models output.



Various generative models differ when it comes to performance and ability, [you can take a look at our integrations page](https://weaviate.io/developers/weaviate/model-providers) to have a better idea of what options you can use. 


- **[Generative Models](./20_generative.mdx)**

## <i class="fa-solid fa-chalkboard"></i> A little extra
### Prompt engineering & Output control
### Context windows

